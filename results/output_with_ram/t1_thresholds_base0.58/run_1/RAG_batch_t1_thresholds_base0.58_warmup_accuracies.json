[
    {
        "score": 0,
        "explanation": 0,
        "request_config": {
            "model": "deepseek-chat",
            "prompt": [
                "Question: [\"what's auph's earnings per share?\", 33]\n Ground truth: 0.4\n Prediction: $-0.55\n",
                91
            ],
            "sampling_params": null,
            "llm_api": "openai_acc",
            "metadata": null
        }
    },
    {
        "score": 1,
        "explanation": 1,
        "request_config": {
            "model": "deepseek-chat",
            "prompt": [
                "Question: [\"what is the etymology of haribo's name?\", 39]\n Ground truth: a syllabic abbreviation formed from hans riegel bonn\n Prediction: haribo is the acronym that comprises the founder's name and the city in which the company was born: hans riegel bonn\n",
                256
            ],
            "sampling_params": null,
            "llm_api": "openai_acc",
            "metadata": null
        }
    },
    {
        "score": -1.0,
        "explanation": -1.0,
        "request_config": {
            "model": "deepseek-chat",
            "prompt": [
                "Question: ['what is the most popular song on billboard in 2024-02-28?', 57]\n Ground truth: texas hold 'em\n Prediction: i don't know\n",
                132
            ],
            "sampling_params": null,
            "llm_api": "openai_acc",
            "metadata": null
        }
    },
    {
        "score": 1,
        "explanation": 1,
        "request_config": {
            "model": "deepseek-chat",
            "prompt": [
                "Question: ['how many islands are there in the philippines', 45]\n Ground truth: the philippines is an archipelago that comprises 7,641 islands\n Prediction: 7,641\n",
                161
            ],
            "sampling_params": null,
            "llm_api": "openai_acc",
            "metadata": null
        }
    },
    {
        "score": 1.0,
        "explanation": 1.0,
        "request_config": {
            "model": "deepseek-chat",
            "prompt": [
                "Question: ['what are the main sections on a balance sheet?', 46]\n Ground truth: assets, liabilities, and equity\n Prediction: assets, liabilities, and equity\n",
                157
            ],
            "sampling_params": null,
            "llm_api": "openai_acc",
            "metadata": null
        }
    },
    {
        "score": -1.0,
        "explanation": -1.0,
        "request_config": {
            "model": "deepseek-chat",
            "prompt": [
                "Question: ['was what happens in vegas the title originally chosen for that movie?', 69]\n Ground truth: yes\n Prediction: i don't know\n",
                133
            ],
            "sampling_params": null,
            "llm_api": "openai_acc",
            "metadata": null
        }
    },
    {
        "score": 0,
        "explanation": 0,
        "request_config": {
            "model": "deepseek-chat",
            "prompt": [
                "Question: ['which cars movie had the higher box office gross worldwide, the first or the second?', 84]\n Ground truth: the second\n Prediction: cars (2006) had a higher box office gross worldwide ($461,983,149) than cars 2 (2011) ($332 million)\n",
                243
            ],
            "sampling_params": null,
            "llm_api": "openai_acc",
            "metadata": null
        }
    },
    {
        "score": -1.0,
        "explanation": -1.0,
        "request_config": {
            "model": "deepseek-chat",
            "prompt": [
                "Question: ['which one of these came out earlier, the greater meaning of water or small town ecstasy?', 88]\n Ground truth: small town ecstasy\n Prediction: i don't know\n",
                167
            ],
            "sampling_params": null,
            "llm_api": "openai_acc",
            "metadata": null
        }
    },
    {
        "score": -1.0,
        "explanation": -1.0,
        "request_config": {
            "model": "deepseek-chat",
            "prompt": [
                "Question: ['on which days did the bq stock closes lower last week?', 54]\n Ground truth: 2024-02-12, 2024-02-13, 2024-02-15, 2024-02-16\n Prediction: i don't know\n",
                161
            ],
            "sampling_params": null,
            "llm_api": "openai_acc",
            "metadata": null
        }
    },
    {
        "score": -1.0,
        "explanation": -1.0,
        "request_config": {
            "model": "deepseek-chat",
            "prompt": [
                "Question: ['what are first ten companies in the dow jones, sorted alphabetically?', 69]\n Ground truth: ten companies in the dow jones are: 3m, american express, amgen, apple, boeing, caterpillar, chenvron, cisco, coca-cola, and disney\n Prediction: i don't know\n",
                261
            ],
            "sampling_params": null,
            "llm_api": "openai_acc",
            "metadata": null
        }
    },
    {
        "score": 1,
        "explanation": 1,
        "request_config": {
            "model": "deepseek-chat",
            "prompt": [
                "Question: ['what has more fat between chicken and lamb?', 43]\n Ground truth: lamb has more fat at 14g compared to chicken breast at 7g\n Prediction: lamb has more fat\n",
                166
            ],
            "sampling_params": null,
            "llm_api": "openai_acc",
            "metadata": null
        }
    },
    {
        "score": -1.0,
        "explanation": -1.0,
        "request_config": {
            "model": "deepseek-chat",
            "prompt": [
                "Question: ['how many nba championships have the golden state warriors won in the past decade?', 81]\n Ground truth: the golden state warriors have won four nba championships in the past decade\n Prediction: i don't know\n",
                218
            ],
            "sampling_params": null,
            "llm_api": "openai_acc",
            "metadata": null
        }
    },
    {
        "score": 0,
        "explanation": 0,
        "request_config": {
            "model": "deepseek-chat",
            "prompt": [
                "Question: [\"during the first week of january 2024, on which days did bkn's stock price reach a higher closing price?\", 104]\n Ground truth: 2024-01-02, 2024-01-03, 2024-01-04\n Prediction: monday 22 january 2024, tuesday 23 january 2024, wednesday 24 january 2024, thursday 25 january 2024, monday 29 january 2024, tuesday 30 january 2024, wednesday 31 january 2024, thursday 1 february 2024, monday 5 february 2024, tuesday 6 february 2024, wednesday 7 february 2024, thursday 8 february 2024\n",
                492
            ],
            "sampling_params": null,
            "llm_api": "openai_acc",
            "metadata": null
        }
    },
    {
        "score": 1.0,
        "explanation": 1.0,
        "request_config": {
            "model": "deepseek-chat",
            "prompt": [
                "Question: ['how many times has trevor noah hosted the grammys?', 50]\n Ground truth: 4\n Prediction: 4\n",
                101
            ],
            "sampling_params": null,
            "llm_api": "openai_acc",
            "metadata": null
        }
    },
    {
        "score": -1.0,
        "explanation": -1.0,
        "request_config": {
            "model": "deepseek-chat",
            "prompt": [
                "Question: ['how many members are part of red hot chili pepper?', 50]\n Ground truth: red hot chili peppers currently has 4 members\n Prediction: i don't know\n",
                156
            ],
            "sampling_params": null,
            "llm_api": "openai_acc",
            "metadata": null
        }
    },
    {
        "score": 1,
        "explanation": 1,
        "request_config": {
            "model": "deepseek-chat",
            "prompt": [
                "Question: [\"nep's current market cap.\", 25]\n Ground truth: $2,543,205,863.73\n Prediction: $2.55b\n",
                97
            ],
            "sampling_params": null,
            "llm_api": "openai_acc",
            "metadata": null
        }
    },
    {
        "score": 1,
        "explanation": 1,
        "request_config": {
            "model": "deepseek-chat",
            "prompt": [
                "Question: [\"what film marked angelina jolie's directorial debut?\", 52]\n Ground truth: in the land of blood and honey released in 2011\n Prediction: in the land of blood and honey\n",
                178
            ],
            "sampling_params": null,
            "llm_api": "openai_acc",
            "metadata": null
        }
    },
    {
        "score": -1.0,
        "explanation": -1.0,
        "request_config": {
            "model": "deepseek-chat",
            "prompt": [
                "Question: ['how many women billionaires are there in the united states as of 2023?', 70]\n Ground truth: 92 as of 2023\n Prediction: i don't know\n",
                144
            ],
            "sampling_params": null,
            "llm_api": "openai_acc",
            "metadata": null
        }
    },
    {
        "score": 1,
        "explanation": 1,
        "request_config": {
            "model": "deepseek-chat",
            "prompt": [
                "Question: ['in which film did leonardo dicaprio and kate winslet first co-star?', 67]\n Ground truth: titanic\n Prediction: titanic (1997)\n",
                137
            ],
            "sampling_params": null,
            "llm_api": "openai_acc",
            "metadata": null
        }
    },
    {
        "score": -1.0,
        "explanation": -1.0,
        "request_config": {
            "model": "deepseek-chat",
            "prompt": [
                "Question: ['who did rihanna co-headline a tour with?', 40]\n Ground truth: rihanna and eminem co-headlined the monster tour in 2014\n Prediction: i don't know\n",
                157
            ],
            "sampling_params": null,
            "llm_api": "openai_acc",
            "metadata": null
        }
    },
    {
        "score": 1,
        "explanation": 1,
        "request_config": {
            "model": "deepseek-chat",
            "prompt": [
                "Question: ['who are the members of the band imagine dragons?', 48]\n Ground truth: the members of imagine dragons are dan reynolds, wayne sermon, ben mckee and daniel platzman\n Prediction: dan reynolds, wayne sermon, ben mckee, and daniel platzman\n",
                247
            ],
            "sampling_params": null,
            "llm_api": "openai_acc",
            "metadata": null
        }
    },
    {
        "score": -1.0,
        "explanation": -1.0,
        "request_config": {
            "model": "deepseek-chat",
            "prompt": [
                "Question: ['how many actors had roles in both gifted hands: the ben carson story and bone tomahawk?', 87]\n Ground truth: 1\n Prediction: i don't know\n",
                149
            ],
            "sampling_params": null,
            "llm_api": "openai_acc",
            "metadata": null
        }
    },
    {
        "score": -1.0,
        "explanation": -1.0,
        "request_config": {
            "model": "deepseek-chat",
            "prompt": [
                "Question: ['how many songs are in adele\\'s \"21\"?', 35]\n Ground truth: there are 11 songs in the album\n Prediction: i don't know\n",
                128
            ],
            "sampling_params": null,
            "llm_api": "openai_acc",
            "metadata": null
        }
    },
    {
        "score": 1,
        "explanation": 1,
        "request_config": {
            "model": "deepseek-chat",
            "prompt": [
                "Question: ['what was taylor swifts age when she released her debut album?', 61]\n Ground truth: 16 years old\n Prediction: 16\n",
                124
            ],
            "sampling_params": null,
            "llm_api": "openai_acc",
            "metadata": null
        }
    },
    {
        "score": -1.0,
        "explanation": -1.0,
        "request_config": {
            "model": "deepseek-chat",
            "prompt": [
                "Question: [\"who made the creative decisions for madea's big happy family?\", 61]\n Ground truth: tyler perry\n Prediction: i don't know\n",
                133
            ],
            "sampling_params": null,
            "llm_api": "openai_acc",
            "metadata": null
        }
    },
    {
        "score": -1.0,
        "explanation": -1.0,
        "request_config": {
            "model": "deepseek-chat",
            "prompt": [
                "Question: ['what was the total amount of corporate bonds issued in the united states in 2020?', 81]\n Ground truth: the total amount of corporate bonds issued in the united states in 2020 was $1.189 trillion\n Prediction: i don't know\n",
                233
            ],
            "sampling_params": null,
            "llm_api": "openai_acc",
            "metadata": null
        }
    },
    {
        "score": -1.0,
        "explanation": -1.0,
        "request_config": {
            "model": "deepseek-chat",
            "prompt": [
                "Question: ['what is the price-to-earnings ratio of haia', 43]\n Ground truth: i don't know\n Prediction: i don't know\n",
                116
            ],
            "sampling_params": null,
            "llm_api": "openai_acc",
            "metadata": null
        }
    },
    {
        "score": -1.0,
        "explanation": -1.0,
        "request_config": {
            "model": "deepseek-chat",
            "prompt": [
                "Question: ['which movie has a higher number of sequels, toy story or the matrix?', 68]\n Ground truth: they both have 4 movies total in their franchises\n Prediction: i don't know\n",
                178
            ],
            "sampling_params": null,
            "llm_api": "openai_acc",
            "metadata": null
        }
    },
    {
        "score": 1,
        "explanation": 1,
        "request_config": {
            "model": "deepseek-chat",
            "prompt": [
                "Question: [\"what are the names of rihanna's albums in chronological order?\", 62]\n Ground truth: music of the sun (2005), a girl like me (2006), good girl gone bad (2007), rated r (2009), loud (2010), talk that talk (2011), unapologetic (2012), and anti (2016)\n Prediction: music of the sun (2005), a girl like me (2006), good girl gone bad (2007), rated r (2009), loud (2010), talk that talk (2011), unapologetic (2012), anti (2016)\n",
                433
            ],
            "sampling_params": null,
            "llm_api": "openai_acc",
            "metadata": null
        }
    },
    {
        "score": -1.0,
        "explanation": -1.0,
        "request_config": {
            "model": "deepseek-chat",
            "prompt": [
                "Question: ['which player has the most consecutive stolen bases in mlb history without being caught since 1980?', 98]\n Ground truth: vince coleman has the most consecutive stolen bases in mlb history without being caught, with 50 stolen bases\n Prediction: i don't know\n",
                268
            ],
            "sampling_params": null,
            "llm_api": "openai_acc",
            "metadata": null
        }
    },
    {
        "score": -1.0,
        "explanation": -1.0,
        "request_config": {
            "model": "deepseek-chat",
            "prompt": [
                "Question: ['what is the language that the man who lost himself was released in?', 67]\n Ground truth: en\n Prediction: i don't know\n",
                130
            ],
            "sampling_params": null,
            "llm_api": "openai_acc",
            "metadata": null
        }
    },
    {
        "score": -1.0,
        "explanation": -1.0,
        "request_config": {
            "model": "deepseek-chat",
            "prompt": [
                "Question: ['which player has the most career home runs in major league baseball among players who have never won a home run title?', 118]\n Ground truth: rafael palmeiro has the most career home runs in major league baseball among players who have never won a home run title, with 569 home runs\n Prediction: i don't know\n",
                320
            ],
            "sampling_params": null,
            "llm_api": "openai_acc",
            "metadata": null
        }
    },
    {
        "score": -1.0,
        "explanation": -1.0,
        "request_config": {
            "model": "deepseek-chat",
            "prompt": [
                "Question: ['which wta player had a higher singles ranking to end last year, madison keys or daria kasatkina?', 96]\n Ground truth: madison keys\n Prediction: i don't know\n",
                169
            ],
            "sampling_params": null,
            "llm_api": "openai_acc",
            "metadata": null
        }
    },
    {
        "score": -1.0,
        "explanation": -1.0,
        "request_config": {
            "model": "deepseek-chat",
            "prompt": [
                "Question: [\"what was tbmc's closing price yesterday?\", 40]\n Ground truth: $10.53\n Prediction: i don't know\n",
                107
            ],
            "sampling_params": null,
            "llm_api": "openai_acc",
            "metadata": null
        }
    },
    {
        "score": 0,
        "explanation": 0,
        "request_config": {
            "model": "deepseek-chat",
            "prompt": [
                "Question: ['how many singers do westlife have?', 34]\n Ground truth: 5\n Prediction: 4\n",
                85
            ],
            "sampling_params": null,
            "llm_api": "openai_acc",
            "metadata": null
        }
    },
    {
        "score": 0.0,
        "explanation": 0.0,
        "request_config": {
            "model": "deepseek-chat",
            "prompt": [
                "Question: ['when did meryl streep stop performing?', 38]\n Ground truth: invalid question\n Prediction: 2006\n",
                107
            ],
            "sampling_params": null,
            "llm_api": "openai_acc",
            "metadata": null
        }
    },
    {
        "score": 1,
        "explanation": 1,
        "request_config": {
            "model": "deepseek-chat",
            "prompt": [
                "Question: ['who won the nobel prize in physics in 2022 from usa', 51]\n Ground truth: john f clauser\n Prediction: john f. clauser\n",
                129
            ],
            "sampling_params": null,
            "llm_api": "openai_acc",
            "metadata": null
        }
    },
    {
        "score": 0,
        "explanation": 0,
        "request_config": {
            "model": "deepseek-chat",
            "prompt": [
                "Question: [\"on their last game day in eng-premier league, what was manchester city's record in terms of wins and losses?\", 108]\n Ground truth: d\n Prediction: 19-6-3\n",
                165
            ],
            "sampling_params": null,
            "llm_api": "openai_acc",
            "metadata": null
        }
    },
    {
        "score": 1,
        "explanation": 1,
        "request_config": {
            "model": "deepseek-chat",
            "prompt": [
                "Question: ['do you know who the director of katherine ryan: in trouble is?', 62]\n Ground truth: colin dench\n Prediction: yes. colin dench\n",
                138
            ],
            "sampling_params": null,
            "llm_api": "openai_acc",
            "metadata": null
        }
    },
    {
        "score": 0,
        "explanation": 0,
        "request_config": {
            "model": "deepseek-chat",
            "prompt": [
                "Question: ['what is the market share of microsoft in the cloud computing industry compared to its competitors?', 98]\n Ground truth: 22%\n Prediction: 23%\n",
                153
            ],
            "sampling_params": null,
            "llm_api": "openai_acc",
            "metadata": null
        }
    },
    {
        "score": 1.0,
        "explanation": 1.0,
        "request_config": {
            "model": "deepseek-chat",
            "prompt": [
                "Question: ['how many years did barack obama serve as president for usa', 58]\n Ground truth: 8 years\n Prediction: 8 years\n",
                121
            ],
            "sampling_params": null,
            "llm_api": "openai_acc",
            "metadata": null
        }
    },
    {
        "score": -1.0,
        "explanation": -1.0,
        "request_config": {
            "model": "deepseek-chat",
            "prompt": [
                "Question: ['which law school has a longer history, monterey college of law or san joaquin college of law?', 93]\n Ground truth: san joaquin college of law\n Prediction: i don't know\n",
                180
            ],
            "sampling_params": null,
            "llm_api": "openai_acc",
            "metadata": null
        }
    },
    {
        "score": 1.0,
        "explanation": 1.0,
        "request_config": {
            "model": "deepseek-chat",
            "prompt": [
                "Question: ['who has had more number one hits on the us billboard dance/electronic songs chart, calvin harris or the chainsmokers?', 117]\n Ground truth: the chainsmokers\n Prediction: the chainsmokers\n",
                199
            ],
            "sampling_params": null,
            "llm_api": "openai_acc",
            "metadata": null
        }
    },
    {
        "score": 0,
        "explanation": 0,
        "request_config": {
            "model": "deepseek-chat",
            "prompt": [
                "Question: ['when did one for all start performing together?', 47]\n Ground truth: 1993\n Prediction: 1997\n",
                104
            ],
            "sampling_params": null,
            "llm_api": "openai_acc",
            "metadata": null
        }
    },
    {
        "score": -1.0,
        "explanation": -1.0,
        "request_config": {
            "model": "deepseek-chat",
            "prompt": [
                "Question: ['how many tours has beyonc\u00e9 gone on by 2006?', 43]\n Ground truth: beyonc\u00e9 went on one tour herself and co-headlined an additional tour by 2006\n Prediction: i don't know\n",
                180
            ],
            "sampling_params": null,
            "llm_api": "openai_acc",
            "metadata": null
        }
    },
    {
        "score": -1.0,
        "explanation": -1.0,
        "request_config": {
            "model": "deepseek-chat",
            "prompt": [
                "Question: ['what was the global box office revenue for caught up?', 53]\n Ground truth: 6754484\n Prediction: i don't know\n",
                121
            ],
            "sampling_params": null,
            "llm_api": "openai_acc",
            "metadata": null
        }
    },
    {
        "score": -1.0,
        "explanation": -1.0,
        "request_config": {
            "model": "deepseek-chat",
            "prompt": [
                "Question: ['which company in the nasdaq 100 index has the highest return on assets (roa)?', 77]\n Ground truth: the company with the highest roa in the nasdaq 100 index is nvidia, with an roa of 55.67%\n Prediction: i don't know\n",
                227
            ],
            "sampling_params": null,
            "llm_api": "openai_acc",
            "metadata": null
        }
    },
    {
        "score": -1.0,
        "explanation": -1.0,
        "request_config": {
            "model": "deepseek-chat",
            "prompt": [
                "Question: ['what was the opening price of nike stock in january last year?', 62]\n Ground truth: $118.55\n Prediction: i don't know\n",
                130
            ],
            "sampling_params": null,
            "llm_api": "openai_acc",
            "metadata": null
        }
    },
    {
        "score": 0,
        "explanation": 0,
        "request_config": {
            "model": "deepseek-chat",
            "prompt": [
                "Question: ['who directed swiss army man, can you say?', 41]\n Ground truth: daniel scheinert\n Prediction: daniel scheinert and daniel kwan\n",
                138
            ],
            "sampling_params": null,
            "llm_api": "openai_acc",
            "metadata": null
        }
    },
    {
        "score": -1.0,
        "explanation": -1.0,
        "request_config": {
            "model": "deepseek-chat",
            "prompt": [
                "Question: ['who is the youngest player in the san antonio spurs?', 52]\n Ground truth: sidy cissoko is the youngest player of the san antonio spurs\n Prediction: i don't know\n",
                173
            ],
            "sampling_params": null,
            "llm_api": "openai_acc",
            "metadata": null
        }
    },
    {
        "score": -1.0,
        "explanation": -1.0,
        "request_config": {
            "model": "deepseek-chat",
            "prompt": [
                "Question: ['how many times has kanye west won the grammy award for producer of the year?', 76]\n Ground truth: kanye west has never won the grammy award for producer of the year, however he was nominated in 2019\n Prediction: i don't know\n",
                237
            ],
            "sampling_params": null,
            "llm_api": "openai_acc",
            "metadata": null
        }
    },
    {
        "score": -1.0,
        "explanation": -1.0,
        "request_config": {
            "model": "deepseek-chat",
            "prompt": [
                "Question: ['which company in the russell 2000 index has the highest dividend yield?', 71]\n Ground truth: the company with the highest dividend yield in the russell 2000 index is b. riley financial, with a dividend yield of 23.65%\n Prediction: i don't know\n",
                256
            ],
            "sampling_params": null,
            "llm_api": "openai_acc",
            "metadata": null
        }
    },
    {
        "score": 1,
        "explanation": 1,
        "request_config": {
            "model": "deepseek-chat",
            "prompt": [
                "Question: ['what are the four great lakes in michigan?', 42]\n Ground truth: superior, michigan, huron and erie\n Prediction: superior, michigan, huron, and erie\n",
                160
            ],
            "sampling_params": null,
            "llm_api": "openai_acc",
            "metadata": null
        }
    },
    {
        "score": 1,
        "explanation": 1,
        "request_config": {
            "model": "deepseek-chat",
            "prompt": [
                "Question: ['which player has the most career wins in the nfl among quarterbacks who have never been to a super bowl?', 104]\n Ground truth: philip rivers has the most career wins in the nfl among quarterbacks who have never been to a super bowl, with 134 wins\n Prediction: philip rivers\n",
                286
            ],
            "sampling_params": null,
            "llm_api": "openai_acc",
            "metadata": null
        }
    },
    {
        "score": -1.0,
        "explanation": -1.0,
        "request_config": {
            "model": "deepseek-chat",
            "prompt": [
                "Question: ['what was the total number of shares traded for special opportunities fund during the first week of february?', 108]\n Ground truth: 93600\n Prediction: i don't know\n",
                175
            ],
            "sampling_params": null,
            "llm_api": "openai_acc",
            "metadata": null
        }
    },
    {
        "score": -1.0,
        "explanation": -1.0,
        "request_config": {
            "model": "deepseek-chat",
            "prompt": [
                "Question: [\"when did serena williams win their first grand slam title in men's singles tennis?\", 82]\n Ground truth: invalid question\n Prediction: i don't know\n",
                159
            ],
            "sampling_params": null,
            "llm_api": "openai_acc",
            "metadata": null
        }
    },
    {
        "score": -1.0,
        "explanation": -1.0,
        "request_config": {
            "model": "deepseek-chat",
            "prompt": [
                "Question: ['which has a greater market capitalization, tron or mgrm?', 56]\n Ground truth: mgrm\n Prediction: i don't know\n",
                121
            ],
            "sampling_params": null,
            "llm_api": "openai_acc",
            "metadata": null
        }
    },
    {
        "score": 0,
        "explanation": 0,
        "request_config": {
            "model": "deepseek-chat",
            "prompt": [
                "Question: ['what was the number of shares traded for adsk on the final trading day?', 71]\n Ground truth: 951000\n Prediction: 200,916 million\n",
                141
            ],
            "sampling_params": null,
            "llm_api": "openai_acc",
            "metadata": null
        }
    },
    {
        "score": -1.0,
        "explanation": -1.0,
        "request_config": {
            "model": "deepseek-chat",
            "prompt": [
                "Question: ['which animal has a longer gestation period, whale or giraffe?', 61]\n Ground truth: whale\n Prediction: i don't know\n",
                127
            ],
            "sampling_params": null,
            "llm_api": "openai_acc",
            "metadata": null
        }
    },
    {
        "score": 0,
        "explanation": 0,
        "request_config": {
            "model": "deepseek-chat",
            "prompt": [
                "Question: [\"what was the final score of los angeles lakers's game on 2023-05-22?\", 68]\n Ground truth: 111\n Prediction: 113-111\n",
                127
            ],
            "sampling_params": null,
            "llm_api": "openai_acc",
            "metadata": null
        }
    },
    {
        "score": 1.0,
        "explanation": 1.0,
        "request_config": {
            "model": "deepseek-chat",
            "prompt": [
                "Question: ['when was the last time the yankees won the world series?', 56]\n Ground truth: 2009\n Prediction: 2009\n",
                113
            ],
            "sampling_params": null,
            "llm_api": "openai_acc",
            "metadata": null
        }
    },
    {
        "score": -1.0,
        "explanation": -1.0,
        "request_config": {
            "model": "deepseek-chat",
            "prompt": [
                "Question: [\"i'm curious to know, which of the two stars, procyon or arcturus, is the brighter object in the sky?\", 100]\n Ground truth: arcturus\n Prediction: i don't know\n",
                170
            ],
            "sampling_params": null,
            "llm_api": "openai_acc",
            "metadata": null
        }
    },
    {
        "score": -1.0,
        "explanation": -1.0,
        "request_config": {
            "model": "deepseek-chat",
            "prompt": [
                "Question: ['on 2022-10-11, how many points did bulls put up in their game?', 62]\n Ground truth: 127\n Prediction: i don't know\n",
                126
            ],
            "sampling_params": null,
            "llm_api": "openai_acc",
            "metadata": null
        }
    },
    {
        "score": 0,
        "explanation": 0,
        "request_config": {
            "model": "deepseek-chat",
            "prompt": [
                "Question: ['could you provide me with the price-to-earnings ratio of gps?', 61]\n Ground truth: 15.52\n Prediction: 193.70\n",
                121
            ],
            "sampling_params": null,
            "llm_api": "openai_acc",
            "metadata": null
        }
    },
    {
        "score": 0,
        "explanation": 0,
        "request_config": {
            "model": "deepseek-chat",
            "prompt": [
                "Question: ['which children does arnold schwarzenegger have?', 47]\n Ground truth: arnold schwarzenegger has five children, including katherine schwarzenegger, patrick schwarzenegger and joseph baena\n Prediction: katherine, christina, patrick, christopher, and joseph\n",
                266
            ],
            "sampling_params": null,
            "llm_api": "openai_acc",
            "metadata": null
        }
    },
    {
        "score": 1,
        "explanation": 1,
        "request_config": {
            "model": "deepseek-chat",
            "prompt": [
                "Question: ['who is the chair of the federal reserve?', 40]\n Ground truth: jerome powell\n Prediction: jerome h. powell\n",
                118
            ],
            "sampling_params": null,
            "llm_api": "openai_acc",
            "metadata": null
        }
    },
    {
        "score": 0,
        "explanation": 0,
        "request_config": {
            "model": "deepseek-chat",
            "prompt": [
                "Question: ['who were awarded the best new artist from 59th grammy (2016) to 61st grammy (2018)?', 83]\n Ground truth: chance the rapper, alessia cara, dua lipa\n Prediction: 2017: chance the rapper\n2018: alessia cara\n",
                215
            ],
            "sampling_params": null,
            "llm_api": "openai_acc",
            "metadata": null
        }
    },
    {
        "score": -1.0,
        "explanation": -1.0,
        "request_config": {
            "model": "deepseek-chat",
            "prompt": [
                "Question: ['how many kids does justin beiber have?', 38]\n Ground truth: invalid question\n Prediction: i don't know\n",
                115
            ],
            "sampling_params": null,
            "llm_api": "openai_acc",
            "metadata": null
        }
    },
    {
        "score": -1.0,
        "explanation": -1.0,
        "request_config": {
            "model": "deepseek-chat",
            "prompt": [
                "Question: ['which movie had the higher box office earnings, whiplash or the big lebowski?', 77]\n Ground truth: whiplash had a box office earnings, with a profit of $49 million, while the big lebowski earned $46.7 million\n Prediction: i don't know\n",
                247
            ],
            "sampling_params": null,
            "llm_api": "openai_acc",
            "metadata": null
        }
    },
    {
        "score": -1.0,
        "explanation": -1.0,
        "request_config": {
            "model": "deepseek-chat",
            "prompt": [
                "Question: ['what time did the noto earthquake in japan happened in january of 2022', 70]\n Ground truth: invalid question\n Prediction: i don't know\n",
                147
            ],
            "sampling_params": null,
            "llm_api": "openai_acc",
            "metadata": null
        }
    },
    {
        "score": 0,
        "explanation": 0,
        "request_config": {
            "model": "deepseek-chat",
            "prompt": [
                "Question: ['i need to know the area codes for the atlanta. can you help?', 60]\n Ground truth: 404, 678, 470, 943, 770\n Prediction: 404, 470, 678, and 770\n",
                154
            ],
            "sampling_params": null,
            "llm_api": "openai_acc",
            "metadata": null
        }
    },
    {
        "score": -1.0,
        "explanation": -1.0,
        "request_config": {
            "model": "deepseek-chat",
            "prompt": [
                "Question: ['how many different record labels has eminem been signed for?', 60]\n Ground truth: throughout his career, eminem has been signed to 5 different record labels\n Prediction: i don't know\n",
                195
            ],
            "sampling_params": null,
            "llm_api": "openai_acc",
            "metadata": null
        }
    },
    {
        "score": -1.0,
        "explanation": -1.0,
        "request_config": {
            "model": "deepseek-chat",
            "prompt": [
                "Question: ['who has been in more stage productions, idris elba or denzel washington?', 72]\n Ground truth: denzel washington has been in more stage productions than idris elba , with his roles in plays like \"fences\" and \"a raisin in the sun\", while elba has primarily focused on film and tv roles, with only a few stage appearances in plays like \"hamlet\" and \"the wire\"\n Prediction: i don't know\n",
                395
            ],
            "sampling_params": null,
            "llm_api": "openai_acc",
            "metadata": null
        }
    },
    {
        "score": 1.0,
        "explanation": 1.0,
        "request_config": {
            "model": "deepseek-chat",
            "prompt": [
                "Question: ['who ordered the building of the blue mosque, tabriz?', 52]\n Ground truth: jahan shah\n Prediction: jahan shah\n",
                121
            ],
            "sampling_params": null,
            "llm_api": "openai_acc",
            "metadata": null
        }
    },
    {
        "score": -1.0,
        "explanation": -1.0,
        "request_config": {
            "model": "deepseek-chat",
            "prompt": [
                "Question: ['who has had a longer career in music, the beattles or elvis presley?', 68]\n Ground truth: elvis presley\n Prediction: i don't know\n",
                142
            ],
            "sampling_params": null,
            "llm_api": "openai_acc",
            "metadata": null
        }
    },
    {
        "score": 0,
        "explanation": 0,
        "request_config": {
            "model": "deepseek-chat",
            "prompt": [
                "Question: ['what is the total market worth of indb as of today?', 51]\n Ground truth: $2,256,297,068.58\n Prediction: $2.464 b\n",
                125
            ],
            "sampling_params": null,
            "llm_api": "openai_acc",
            "metadata": null
        }
    },
    {
        "score": -1.0,
        "explanation": -1.0,
        "request_config": {
            "model": "deepseek-chat",
            "prompt": [
                "Question: ['what year did ben-hur win the most academy awards in a single year, including best picture, best director, and best actress?', 124]\n Ground truth: invalid question\n Prediction: i don't know\n",
                202
            ],
            "sampling_params": null,
            "llm_api": "openai_acc",
            "metadata": null
        }
    },
    {
        "score": -1.0,
        "explanation": -1.0,
        "request_config": {
            "model": "deepseek-chat",
            "prompt": [
                "Question: ['who has won more american music awards, drake or kendrick lamar?', 64]\n Ground truth: drake has won more american music awards than kendrick lamar, with eight wins compared to kendrick's 4 wins\n Prediction: i don't know\n",
                232
            ],
            "sampling_params": null,
            "llm_api": "openai_acc",
            "metadata": null
        }
    },
    {
        "score": -1.0,
        "explanation": -1.0,
        "request_config": {
            "model": "deepseek-chat",
            "prompt": [
                "Question: ['how many people live in the smallest state in the us by area?', 61]\n Ground truth: the smallest state in the us by area, rhode island, has a population of 1,097,379\n Prediction: i don't know\n",
                203
            ],
            "sampling_params": null,
            "llm_api": "openai_acc",
            "metadata": null
        }
    },
    {
        "score": -1.0,
        "explanation": -1.0,
        "request_config": {
            "model": "deepseek-chat",
            "prompt": [
                "Question: ['how many minarets does al-muhdhar mosque have?', 46]\n Ground truth: 1\n Prediction: i don't know\n",
                108
            ],
            "sampling_params": null,
            "llm_api": "openai_acc",
            "metadata": null
        }
    },
    {
        "score": -1.0,
        "explanation": -1.0,
        "request_config": {
            "model": "deepseek-chat",
            "prompt": [
                "Question: [\"what's the current score of rayo vallecano's game today?\", 56]\n Ground truth: invalid question\n Prediction: i don't know\n",
                133
            ],
            "sampling_params": null,
            "llm_api": "openai_acc",
            "metadata": null
        }
    },
    {
        "score": -1.0,
        "explanation": -1.0,
        "request_config": {
            "model": "deepseek-chat",
            "prompt": [
                "Question: ['which company has a higher price-to-book ratio, splunk or mongodb?', 66]\n Ground truth: as of the current financial data, splunk has a higher price-to-book ratio than mongodb, with a price-to-book ratio of 132.33 compared to mongodb's 32.98\n Prediction: i don't know\n",
                279
            ],
            "sampling_params": null,
            "llm_api": "openai_acc",
            "metadata": null
        }
    },
    {
        "score": 0,
        "explanation": 0,
        "request_config": {
            "model": "deepseek-chat",
            "prompt": [
                "Question: [\"how old is dave franco's oldest brother?\", 40]\n Ground truth: dave franco's oldest brother, james franco, is 45 years old\n Prediction: 38 years old\n",
                160
            ],
            "sampling_params": null,
            "llm_api": "openai_acc",
            "metadata": null
        }
    },
    {
        "score": 1,
        "explanation": 1,
        "request_config": {
            "model": "deepseek-chat",
            "prompt": [
                "Question: ['what is the largest national park in the us?', 44]\n Ground truth: wrangell-st. elias national park & preserve\n Prediction: wrangell st elias national park\n",
                167
            ],
            "sampling_params": null,
            "llm_api": "openai_acc",
            "metadata": null
        }
    },
    {
        "score": -1.0,
        "explanation": -1.0,
        "request_config": {
            "model": "deepseek-chat",
            "prompt": [
                "Question: ['for the fall of saigon, can you tell me who was the main director?', 66]\n Ground truth: michael dutfield\n Prediction: i don't know\n",
                143
            ],
            "sampling_params": null,
            "llm_api": "openai_acc",
            "metadata": null
        }
    },
    {
        "score": -1.0,
        "explanation": -1.0,
        "request_config": {
            "model": "deepseek-chat",
            "prompt": [
                "Question: ['which company in the nasdaq 100 index has the highest ratio of green energy usage?', 82]\n Ground truth: the company with the highest percentage of renewable energy usage in the nasdaq 100 index is google (alphabet), with over 106% of its total power usage coming from green energy\n Prediction: i don't know\n",
                319
            ],
            "sampling_params": null,
            "llm_api": "openai_acc",
            "metadata": null
        }
    },
    {
        "score": 0,
        "explanation": 0,
        "request_config": {
            "model": "deepseek-chat",
            "prompt": [
                "Question: ['in 1990 who received the best actor oscar for their outstanding performance in a movie?', 87]\n Ground truth: daniel day lewis\n Prediction: jeremy irons for \"reversal of fortune\"\n",
                190
            ],
            "sampling_params": null,
            "llm_api": "openai_acc",
            "metadata": null
        }
    },
    {
        "score": -1.0,
        "explanation": -1.0,
        "request_config": {
            "model": "deepseek-chat",
            "prompt": [
                "Question: ['what year did david cassidy release their hit song \"white horse\"?', 65]\n Ground truth: invalid question\n Prediction: i don't know\n",
                142
            ],
            "sampling_params": null,
            "llm_api": "openai_acc",
            "metadata": null
        }
    },
    {
        "score": -1.0,
        "explanation": -1.0,
        "request_config": {
            "model": "deepseek-chat",
            "prompt": [
                "Question: [\"what was dallas mavericks's win tally in 2022?\", 46]\n Ground truth: 67\n Prediction: i don't know\n",
                109
            ],
            "sampling_params": null,
            "llm_api": "openai_acc",
            "metadata": null
        }
    },
    {
        "score": -1.0,
        "explanation": -1.0,
        "request_config": {
            "model": "deepseek-chat",
            "prompt": [
                "Question: ['which artist was younger, alice cooper or nina simone?', 54]\n Ground truth: alice cooper\n Prediction: i don't know\n",
                127
            ],
            "sampling_params": null,
            "llm_api": "openai_acc",
            "metadata": null
        }
    },
    {
        "score": -1.0,
        "explanation": -1.0,
        "request_config": {
            "model": "deepseek-chat",
            "prompt": [
                "Question: ['on which day did the gdev inc. warrant distribute dividends in the last year?', 77]\n Ground truth: none of the days\n Prediction: i don't know\n",
                154
            ],
            "sampling_params": null,
            "llm_api": "openai_acc",
            "metadata": null
        }
    },
    {
        "score": -1.0,
        "explanation": -1.0,
        "request_config": {
            "model": "deepseek-chat",
            "prompt": [
                "Question: [\"where did g. p. nerli paint whistler's mother?\", 46]\n Ground truth: invalid question\n Prediction: i don't know\n",
                123
            ],
            "sampling_params": null,
            "llm_api": "openai_acc",
            "metadata": null
        }
    },
    {
        "score": 1,
        "explanation": 1,
        "request_config": {
            "model": "deepseek-chat",
            "prompt": [
                "Question: ['how many masters has tiger woods won?', 37]\n Ground truth: 5 times\n Prediction: 5\n",
                94
            ],
            "sampling_params": null,
            "llm_api": "openai_acc",
            "metadata": null
        }
    },
    {
        "score": -1.0,
        "explanation": -1.0,
        "request_config": {
            "model": "deepseek-chat",
            "prompt": [
                "Question: ['in 2021-12, which teams were able to take down houston rockets and come out on top?', 83]\n Ground truth: charlotte hornets, chicago bulls, cleveland cavaliers, indiana pacers, los angeles lakers, memphis grizzlies, miami heat, milwaukee bucks, new york knicks\n Prediction: i don't know\n",
                298
            ],
            "sampling_params": null,
            "llm_api": "openai_acc",
            "metadata": null
        }
    },
    {
        "score": -1.0,
        "explanation": -1.0,
        "request_config": {
            "model": "deepseek-chat",
            "prompt": [
                "Question: ['who among patricia place and lana clarkson is younger?', 54]\n Ground truth: lana clarkson\n Prediction: i don't know\n",
                128
            ],
            "sampling_params": null,
            "llm_api": "openai_acc",
            "metadata": null
        }
    },
    {
        "score": -1.0,
        "explanation": -1.0,
        "request_config": {
            "model": "deepseek-chat",
            "prompt": [
                "Question: ['how many times has brooks koepka won the masters tournament?', 60]\n Ground truth: invalid question\n Prediction: i don't know\n",
                137
            ],
            "sampling_params": null,
            "llm_api": "openai_acc",
            "metadata": null
        }
    },
    {
        "score": -1.0,
        "explanation": -1.0,
        "request_config": {
            "model": "deepseek-chat",
            "prompt": [
                "Question: ['when forest whitaker won his/her first oscar best actor, which movie won the best picture?', 90]\n Ground truth: the departed\n Prediction: i don't know\n",
                163
            ],
            "sampling_params": null,
            "llm_api": "openai_acc",
            "metadata": null
        }
    },
    {
        "score": 1,
        "explanation": 1,
        "request_config": {
            "model": "deepseek-chat",
            "prompt": [
                "Question: ['which one has the higher trading volume on the last trading day, sbux or  hsic?', 79]\n Ground truth: sbux\n Prediction: 710,978 (sbux) vs 204,820 (hsic)\n",
                164
            ],
            "sampling_params": null,
            "llm_api": "openai_acc",
            "metadata": null
        }
    },
    {
        "score": 0,
        "explanation": 0,
        "request_config": {
            "model": "deepseek-chat",
            "prompt": [
                "Question: ['what ended the war of 1812?', 27]\n Ground truth: on february 16, 1815, the day president james madison sent the treaty of ghent to the senate, senators approved it unanimously. with ratification of this treaty, the war of 1812 came to an end\n Prediction: the battle of new orleans, january 8, 1815, and the ratification of the treaty of ghent on february 17, 1815\n",
                376
            ],
            "sampling_params": null,
            "llm_api": "openai_acc",
            "metadata": null
        }
    },
    {
        "score": -1.0,
        "explanation": -1.0,
        "request_config": {
            "model": "deepseek-chat",
            "prompt": [
                "Question: ['how many times has taylor swift won the billboard award for best country artist?', 80]\n Ground truth: taylor swift has won the billboard award for best country artist two times, in 2013 and 2022\n Prediction: i don't know\n",
                233
            ],
            "sampling_params": null,
            "llm_api": "openai_acc",
            "metadata": null
        }
    }
]